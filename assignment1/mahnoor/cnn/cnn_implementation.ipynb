{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4733317f-dcad-40b4-aa6c-5594d8e069f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "3b47f4bb-60e1-4520-9ab0-3c26372a5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_data(DATA_PATH, BATCH_SIZE):\n",
    "    try:\n",
    "        mnist_training_dataset = datasets.MNIST(root=DATAPATH+'train', train=True, download=True, transform=ToTensor())\n",
    "        mnist_testing_dataset = datasets.MNIST(root=DATAPATH+'test', train=False, download=True, transform=ToTensor())\n",
    "        \n",
    "        training_dataset, validation_dataset = random_split(mnist_training_dataset, [int(0.8*len(mnist_training_dataset)), int(00.2*len(mnist_training_dataset))])\n",
    "        \n",
    "        train_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "        validation_loader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        test_loader = DataLoader(mnist_testing_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "        \n",
    "        return train_loader, validation_loader, test_loader\n",
    "    \n",
    "    except Exception as e:\n",
    "        print('Unable to get data due to ', e)\n",
    "        \n",
    "def network_training(model, train_loader, validation_loader, criterion, optimizer, training_params):\n",
    "    try:\n",
    "        best_accuracy = 0\n",
    "        loss_history = []\n",
    "        training_acc_history = []\n",
    "        validation_acc_history = []\n",
    "        \n",
    "        for epoch in range(0, training_params['NUM_EPOCHS']):\n",
    "            model.train()\n",
    "            loss_scores = []\n",
    "            training_acc_scores = []\n",
    "            correct_predictions = 0\n",
    "            \n",
    "            for batch_index, (images, targets) in enumerate(train_loader):\n",
    "                images = images.to(training_params['DEVICE'])\n",
    "                targets = targets.to(training_params['DEVICE'])\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss_scores.append(loss.item())\n",
    "                \n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                correct_predictions = (preds==targets).sum().item()\n",
    "                training_acc_scores.append(correct_predictions/targets.shape[0])\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                if (batch_index+1) % 100 == 0:\n",
    "                    print(f\"Epoch : [{epoch+1}/{training_params['NUM_EPOCHS']}] | Step : [{batch_index+1}/{len(train_loader)}] | Loss : {loss.item()} \")\n",
    "            \n",
    "            loss_history.append((sum(loss_scores)/len(loss_scores)))\n",
    "            training_acc_history.append((sum(training_acc_scores)/len(training_acc_scores))*100)      \n",
    "            print(f'Epoch : {epoch+1} | Loss : {loss_history[-1]} | Training Accuracy : {training_acc_history[-1]}%')\n",
    "       \n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                correct_predictions = 0\n",
    "                validation_acc_scores = []\n",
    "\n",
    "                for images, targets in iter(validation_loader):\n",
    "                    images = images.to(training_params['DEVICE'])\n",
    "                    targets = targets.to(training_params['DEVICE'])\n",
    "                                \n",
    "                    outputs = model(images)\n",
    "\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    correct_predictions = (preds == targets).sum().item()\n",
    "                    validation_acc_scores.append(correct_predictions/targets.shape[0])\n",
    "\n",
    "                validation_acc_history.append((sum(validation_acc_scores)/len(validation_acc_scores))*100)\n",
    "                print(f'Epoch {epoch+1} | Validation Accuracy {validation_acc_history[-1]}%')\n",
    "\n",
    "                if validation_acc_history[-1]>best_accuracy:\n",
    "                    best_accuracy = validation_acc_history[-1]\n",
    "                    print('Saving the model...')\n",
    "                    torch.save(model.state_dict(), f\"Accuracy_{best_accuracy}_batchsize_{training_params['BATCH_SIZE']}_lr_{training_params['LEARNING_RATE']}.ckpt\")\n",
    "                \n",
    "        return loss_history\n",
    "    except Exception as e:\n",
    "        print('Error occured in training method = ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1742a790-dd85-4713-a326-121959ef1fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Network(nn.Module):\n",
    "    def __init__(self, model_params):\n",
    "        try:\n",
    "            super(CNN_Network, self).__init__()\n",
    "            \n",
    "            layers = []\n",
    "            \n",
    "            for input_channel, out_channel in zip([model_params['INPUT_SIZE']] + model_params['HIDDEN_LAYERS'][:-1], \n",
    "                                                     model_params['HIDDEN_LAYERS'][:len(model_params['HIDDEN_LAYERS'])]):\n",
    "                layers.append(nn.Conv2d(input_channel, out_channel, model_params['KERNEL'], model_params['STRIDE'], model_params['PADDING'], bias=True))\n",
    "                layers.append(nn.MaxPool2d(2, 2))\n",
    "                layers.append(nn.ReLU())\n",
    "            layers.append(nn.Flatten(1))      \n",
    "            layers.append(nn.Linear(model_params['HIDDEN_LAYERS'][-1], model_params['OUTPUT_SIZE'], bias=True))\n",
    "\n",
    "            self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('initializing failed due to ', e)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            return self.layers(x)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('forward pass failed due to ', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ef59d73f-1a13-40a9-a498-39ba298ad040",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0\n",
      "Network structure is: <bound method Module.parameters of CNN_Network(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(1, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(160, 100, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): ReLU()\n",
      "    (6): Conv2d(100, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): ReLU()\n",
      "    (9): Conv2d(64, 10, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (11): ReLU()\n",
      "    (12): Flatten(start_dim=1, end_dim=-1)\n",
      "    (13): Linear(in_features=10, out_features=10, bias=True)\n",
      "  )\n",
      ")>\n",
      "Total number of parameters: 209244\n",
      "Epoch : [1/3] | Step : [100/750] | Loss : 0.5298232436180115 \n",
      "Epoch : [1/3] | Step : [200/750] | Loss : 0.21234865486621857 \n",
      "Epoch : [1/3] | Step : [300/750] | Loss : 0.13404595851898193 \n",
      "Epoch : [1/3] | Step : [400/750] | Loss : 0.10029985755681992 \n",
      "Epoch : [1/3] | Step : [500/750] | Loss : 0.08578576892614365 \n",
      "Epoch : [1/3] | Step : [600/750] | Loss : 0.12813736498355865 \n",
      "Epoch : [1/3] | Step : [700/750] | Loss : 0.22410663962364197 \n",
      "Epoch : 1 | Loss : 0.3573124853186309 | Training Accuracy : 88.71875%\n",
      "Epoch 1 | Validation Accuracy 97.06666666666666%\n",
      "Saving the model...\n",
      "Epoch : [2/3] | Step : [100/750] | Loss : 0.03116798959672451 \n",
      "Epoch : [2/3] | Step : [200/750] | Loss : 0.17936478555202484 \n",
      "Epoch : [2/3] | Step : [300/750] | Loss : 0.01997082121670246 \n",
      "Epoch : [2/3] | Step : [400/750] | Loss : 0.011367076076567173 \n",
      "Epoch : [2/3] | Step : [500/750] | Loss : 0.0797298476099968 \n",
      "Epoch : [2/3] | Step : [600/750] | Loss : 0.129547581076622 \n",
      "Epoch : [2/3] | Step : [700/750] | Loss : 0.052246011793613434 \n",
      "Epoch : 2 | Loss : 0.09501730705673496 | Training Accuracy : 97.16041666666668%\n",
      "Epoch 2 | Validation Accuracy 98.20416666666667%\n",
      "Saving the model...\n",
      "Epoch : [3/3] | Step : [100/750] | Loss : 0.006755842361599207 \n",
      "Epoch : [3/3] | Step : [200/750] | Loss : 0.06806100904941559 \n",
      "Epoch : [3/3] | Step : [300/750] | Loss : 0.063258096575737 \n",
      "Epoch : [3/3] | Step : [400/750] | Loss : 0.021135471761226654 \n",
      "Epoch : [3/3] | Step : [500/750] | Loss : 0.011407691054046154 \n",
      "Epoch : [3/3] | Step : [600/750] | Loss : 0.04186837375164032 \n",
      "Epoch : [3/3] | Step : [700/750] | Loss : 0.039451368153095245 \n",
      "Epoch : 3 | Loss : 0.06464011678860213 | Training Accuracy : 98.07708333333333%\n",
      "Epoch 3 | Validation Accuracy 98.875%\n",
      "Saving the model...\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__' :\n",
    "    \n",
    "    print(torch.__version__)\n",
    "    \n",
    "    DATA_PATH = 'D:\\Repos\\MLCS_Project_Assignments\\\\'\n",
    "    \n",
    "    training_params = {\n",
    "        'DEVICE' : torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "        'BATCH_SIZE' : 64,\n",
    "        'LEARNING_RATE' : 0.001,\n",
    "        'NUM_EPOCHS' : 3\n",
    "    }\n",
    "    \n",
    "    model_params = {\n",
    "        'INPUT_SIZE' : 1,\n",
    "        'HIDDEN_LAYERS' : [160, 100, 64, 10],\n",
    "        'OUTPUT_SIZE' : 10,\n",
    "        'KERNEL' : 3,\n",
    "        'STRIDE' : 1,\n",
    "        'PADDING' : 1\n",
    "    }\n",
    "    \n",
    "    train_loader, validation_loader, test_loader = _get_data(DATA_PATH, training_params['BATCH_SIZE'])\n",
    "    \n",
    "    network = CNN_Network(model_params).to(training_params['DEVICE'])\n",
    "    print(f'Network structure is: {network.parameters}')\n",
    "    print(f'Total number of parameters: {sum(p.numel() for p in network.parameters())}')\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss().to(training_params['DEVICE'])\n",
    "    optimizer = optim.Adam(network.parameters(), lr=training_params['LEARNING_RATE'])\n",
    "\n",
    "    loss = network_training(network, train_loader, validation_loader, criterion, optimizer, training_params)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "835f3a3f-40af-4a76-bc30-0725be498cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, targets = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7d9304ec-d51c-47f0-87d9-cb0b4674dff3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1, 28, 28])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef20c45d-2f16-4e58-ab61-f393a7f682e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(targets.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "92b5a495-5eab-406c-a3c2-9625647d4831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 98.4375\n"
     ]
    }
   ],
   "source": [
    "network.load_state_dict(torch.load(\"Accuracy_98.875_batchsize_64_lr_0.001.ckpt\"))\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct_predictions = 0\n",
    "    test_images = 0\n",
    "    testing_acc_history = []\n",
    "\n",
    "    for images, targets in iter(test_loader):\n",
    "        images = images.to(training_params['DEVICE'])\n",
    "        targets = targets.to(training_params['DEVICE'])\n",
    "        \n",
    "        outputs = network(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_predictions = (preds==targets).sum().item()\n",
    "        test_images += targets.shape[0]\n",
    "        testing_acc_history.append(correct_predictions/targets.shape[0])\n",
    "    \n",
    "    print(f'Accuracy of the network on the {test_images} test images: {(sum(testing_acc_history)/len(testing_acc_history))*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc5d3f-ce87-4f47-b1d2-f72858f5d953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
