{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qKo3S_fOsMim"
   },
   "source": [
    "# ML in Cybersecurity: Task 3\n",
    "\n",
    "## Team\n",
    "  * **Team name**:  *R2D2C3P0BB8*\n",
    "  * **Members**:  <br/> **Navdeeppal Singh (s8nlsing@stud.uni-saarland.de)** <br/> **Shahrukh Khan (shkh00001@stud.uni-saarland.de)** <br/> **Mahnoor Shahid (mash00001@stud.uni-saarland.de)**\n",
    "\n",
    "\n",
    "## Logistics\n",
    "  * **Due date**: 9th December 2021, 23:59:59\n",
    "  * Email the completed notebook to: `mlcysec_ws2022_staff@lists.cispa.saarland`\n",
    "  * Complete this in **teams of 3**\n",
    "  * Feel free to use the forum to discuss.\n",
    "  \n",
    "## Timeline\n",
    "  * 26-Nov-2021: hand-out\n",
    "  * **09-Dec-2021**: Email completed notebook\n",
    "  \n",
    "  \n",
    "## About this Project\n",
    "In this project, you will explore an application of ML to a popular task in cybersecurity: malware classification.\n",
    "You will be presented with precomputed behaviour analysis reports of thousands of program binaries, many of which are malwares.\n",
    "Your goal is to train a malware detector using this behavioural reports.\n",
    "\n",
    "\n",
    "## A Note on Grading\n",
    "The grading for this project will depend on:\n",
    " 1. Vectorizing Inputs\n",
    "   * Obtaining a reasonable vectorized representations of the input data (a file containing a sequence of system calls)\n",
    "   * Understanding the influence these representations have on your model\n",
    " 1. Classification Model  \n",
    "   * Following a clear ML pipeline\n",
    "   * Obtaining reasonable performances (>60\\%) on held-out test set\n",
    "   * Choice of evaluation metric\n",
    "   * Visualizing loss/accuracy curves\n",
    " 1. Analysis\n",
    "   * Which methods (input representations/ML models) work better than the rest and why?\n",
    "   * Which hyper-parameters and design-choices were important in each of your methods?\n",
    "   * Quantifying influence of these hyper-parameters on loss and/or validation accuracies\n",
    "   * Trade-offs between methods, hyper-parameters, design-choices\n",
    "   * Anything else you find interesting (this part is open-ended)\n",
    "\n",
    "\n",
    "## Grading Details\n",
    " * 40 points: Vectorizing input data (each input = behaviour analysis file in our case)\n",
    " * 40 points: Training a classification model\n",
    " * 15 points: Analysis/Discussion\n",
    " * 5 points: Clean code\n",
    " \n",
    "## Filling-in the Notebook\n",
    "You'll be submitting this very notebook that is filled-in with your code and analysis. Make sure you submit one that has been previously executed in-order. (So that results/graphs are already visible upon opening it). \n",
    "\n",
    "The notebook you submit **should compile** (or should be self-contained and sufficiently commented). Check tutorial 1 on how to set up the Python3 environment.\n",
    "\n",
    "\n",
    "**The notebook is your project report. So, to make the report readable, omit code for techniques/models/things that did not work. You can use the final summary to provide a report about these.**\n",
    "\n",
    "It is extremely important that you **do not** re-order the existing sections. Apart from that, the code blocks that you need to fill-in are given by:\n",
    "```\n",
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "#\n",
    "```\n",
    "Feel free to break this into multiple-cells. It's even better if you interleave explanations and code-blocks so that the entire notebook forms a readable \"story\".\n",
    "\n",
    "\n",
    "## Code of Honor\n",
    "We encourage discussing ideas and concepts with other students to help you learn and better understand the course content. However, the work you submit and present **must be original** and demonstrate your effort in solving the presented problems. **We will not tolerate** blatantly using existing solutions (such as from the internet), improper collaboration (e.g., sharing code or experimental data between groups) and plagiarism. If the honor code is not met, no points will be awarded.\n",
    "\n",
    " \n",
    " ## Versions\n",
    "  * v1.1: Updated deadline\n",
    "  * v1.0: Initial notebook\n",
    "  \n",
    "  ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "uyCiLbXbsMiq",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time \n",
    " \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import json \n",
    "import time \n",
    "import pickle \n",
    "import sys \n",
    "import csv \n",
    "import os \n",
    "import os.path as osp \n",
    "import shutil \n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing, naive_bayes\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from IPython.display import display, HTML\n",
    " \n",
    "%matplotlib inline \n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots \n",
    "plt.rcParams['image.interpolation'] = 'nearest' \n",
    "plt.rcParams['image.cmap'] = 'gray' \n",
    " \n",
    "# for auto-reloading external modules \n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7dHogdxRsMis",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Some suggestions of our libraries that might be helpful for this project\n",
    "from collections import Counter          # an even easier way to count\n",
    "from multiprocessing import Pool         # for multiprocessing\n",
    "from tqdm import tqdm                    # fancy progress bars\n",
    "\n",
    "# Load other libraries here.\n",
    "# Keep it minimal! We should be easily able to reproduce your code.\n",
    "\n",
    "# We preload pytorch as an example\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJWkh3GUsMit"
   },
   "source": [
    "# Setup\n",
    "\n",
    "  * Download the datasets: [train](https://nextcloud.mpi-klsb.mpg.de/index.php/s/pJrRGzm2So2PMZm) (128M) and [test](https://nextcloud.mpi-klsb.mpg.de/index.php/s/zN3yeWzQB3i5WqE) (92M)\n",
    "  * Unpack them under `./data/train` and `./data/test`\n",
    "  * Hint: you can execute shell scripts from notebooks using the `!` prefix, e.g., `! wget <url>`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "wlhs4w44sMit"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wc' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'printf' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Check that you are prepared with the data\n",
    "! echo '# train examples (Should be 13682) : '; ls -type f -print data/train | wc -l\n",
    "! printf '# test  examples (Should be 10000) : '; ls data/test | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zh1-JHNIsMiv"
   },
   "source": [
    "Now that you're set, let's briefly look at the data you have been handed.\n",
    "Each file encodes the behavior report of a program (potentially a malware), using an encoding scheme called \"The Malware Instruction Set\" (MIST for short).\n",
    "At this point, we highly recommend you briefly read-up Sec. 2 of the [MIST](http://www.mlsec.org/malheur/docs/mist-tr.pdf) documentation.\n",
    "\n",
    "You will find each file named as `filename.<malwarename>`:\n",
    "```\n",
    "» ls data/train | head\n",
    "00005ecc06ae3e489042e979717bb1455f17ac9d.NothingFound\n",
    "0008e3d188483aeae0de62d8d3a1479bd63ed8c9.Basun\n",
    "000d2eea77ee037b7ef99586eb2f1433991baca9.Patched\n",
    "000d996fa8f3c83c1c5568687bb3883a543ec874.Basun\n",
    "0010f78d3ffee61101068a0722e09a98959a5f2c.Basun\n",
    "0013cd0a8febd88bfc4333e20486bd1a9816fcbf.Basun\n",
    "0014aca72eb88a7f20fce5a4e000c1f7fff4958a.Texel\n",
    "001ffc75f24a0ae63a7033a01b8152ba371f6154.Texel\n",
    "0022d6ba67d556b931e3ab26abcd7490393703c4.Basun\n",
    "0028c307a125cf0fdc97d7a1ffce118c6e560a70.Swizzor\n",
    "...\n",
    "```\n",
    "and within each file, you will see a sequence of individual systems calls monitored duing the run-time of the binary - a malware named 'Basun' in the case:\n",
    "```\n",
    "» head data/train/000d996fa8f3c83c1c5568687bb3883a543ec874.Basun\n",
    "# process 000006c8 0000066a 022c82f4 00000000 thread 0001 #\n",
    "02 01 | 000006c8 0000066a 00015000\n",
    "02 02 | 00006b2c 047c8042 000b9000\n",
    "02 02 | 00006b2c 047c8042 00108000\n",
    "02 02 | 00006b2c 047c8042 00153000\n",
    "02 02 | 00006b2c 047c8042 00091000\n",
    "02 02 | 00006b2c 047c8042 00049000\n",
    "02 02 | 00006b2c 047c8042 000aa000\n",
    "02 02 | 00006b2c 047c8042 00092000\n",
    "02 02 | 00006b2c 047c8042 00011000\n",
    "...\n",
    "```\n",
    "(**Note**: Please ignore the first line that begins with `# process ...`.)\n",
    "\n",
    "Your task in this project is to train a malware detector, which given the sequence of system calls (in the MIST-formatted file like above), predicts one of 10 classes: `{ Agent, Allaple, AutoIt, Basun, NothingFound, Patched, Swizzor, Texel, VB, Virut }`, where `NothingFound` roughly represents no malware is present.\n",
    "In terms of machine learning terminology, your malware detector $F: X \\rightarrow Y$ should learn a mapping from the MIST-encoded behaviour report (the input $x \\in X$) to the malware class $y \\in Y$.\n",
    "\n",
    "Consequently, you will primarily tackle two challenges in this project:\n",
    "  1. \"Vectorizing\" the input data i.e., representing each input (file) as a tensor\n",
    "  1. Training an ML model\n",
    "  \n",
    "\n",
    "### Some tips:\n",
    "  * Begin with an extremely simple representation/ML model and get above chance-level classification performance\n",
    "  * Choose your evaluation metric wisely\n",
    "  * Save intermediate computations (e.g., a token to index mapping). This will avoid you parsing the entire dataset for every experiment\n",
    "  * Try using `multiprocessing.Pool` to parallelize your `for` loops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p8xloR8dsMiv"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXnyDAdbsMiw"
   },
   "source": [
    "# 1. Vectorize Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ia-xFIQtsMiw"
   },
   "source": [
    "## 1.a. Load Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "ZScY-C2IsMiw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def load_content(filepath):\n",
    "    '''Given a filepath, returns (content, classname), where content = [list of lines in file]'''\n",
    "    lines = open(filepath,'r').readlines()\n",
    "    string1 = \"\" \n",
    "    for row in lines:\n",
    "        if not '#' in row:\n",
    "            row = row.replace(' |',' ').strip(' \\n')\n",
    "            string1=string1+row\n",
    "    label = str.split(filepath,'.')[-1]\n",
    "    return label, string1\n",
    "\n",
    "\n",
    "def load_data(data_path, nworkers=10):\n",
    "    '''Returns each data sample as a tuple (x, y), x = sequence of strings (i.e., syscalls), y = malware program class'''\n",
    "    raw_data_samples = []\n",
    "    keys = []\n",
    "    records=[]\n",
    "    all_files = glob.glob(str(data_path) + '/*')\n",
    "    pool = Pool(processes=4)\n",
    "    for file in all_files[:5000]:\n",
    "        # labels, lines = pool.map(load_content, (file))\n",
    "        labels, lines = load_content(file)\n",
    "        keys.append(labels)\n",
    "        records.append(lines)\n",
    "    raw_data_samples = {'label': keys, 'lines': records  }\n",
    "    return raw_data_samples    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "7BSUdq_-sMiw",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading training data ... \n"
     ]
    }
   ],
   "source": [
    "print('=> Loading training data ... ')\n",
    "train_raw_samples = load_data(Path('./data/train'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_raw_samples['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_raw_samples['lines'][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_raw_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification(dff, classes):\n",
    "    data[classes].value_counts().plot(kind='bar', color= 'skyblue')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel('Malware')\n",
    "    plt.title(\"Frequency Count of Malware Classes\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.DataFrame(train_raw_samples)\n",
    "plot_classification(data, classes='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_df(dff):\n",
    "    dff = dff.reset_index()\n",
    "    dff = dff.drop(columns=['index'])\n",
    "    return dff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(dict_samples, validate_size = 0.2, test=False):\n",
    "    dff = pd.DataFrame(dict_samples)\n",
    "    if test == False:\n",
    "        train_samples, validate_samples = train_test_split(dff, test_size = validate_size)\n",
    "        train_samples = reset_df(train_samples)\n",
    "        validate_samples = reset_df(validate_samples)\n",
    "        return  train_samples, validate_samples\n",
    "    else:\n",
    "        test_samples = reset_df(dff)\n",
    "        return  test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "GG6tcSNJsMiw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Samples (4000, 2)\n",
      "Testing Samples (5000, 2)\n",
      "=> # Train samples =  4000\n",
      "=> # Test samples =  5000\n"
     ]
    }
   ],
   "source": [
    "project_mode = 'traintest'    # trainval, traintest, debug\n",
    "np.random.seed(123)          # To perform the same split across multiple runs\n",
    "\n",
    "if project_mode == 'trainval':\n",
    "    train_samples, validate_samples = split_dataset(train_raw_samples, validate_size = 0.25)\n",
    "    # mask = int(len(train_raw_samples))\n",
    "    # train_samples, validate_samples = random_split(train_raw_samples, [int(0.8*mask), int(0.2*mask)])\n",
    "    print(f'Training Samples {train_samples.shape}')\n",
    "    print(f'Validation Samples {validate_samples.shape}')\n",
    "\n",
    "elif project_mode == 'traintest':\n",
    "    train_samples, _ = split_dataset(train_raw_samples, validate_size = 0.2)\n",
    "    test_raw_samples = load_data(Path('./data/test/test'))\n",
    "    test_samples = split_dataset(test_raw_samples, validate_size = 0.0, test =True)\n",
    "    print(f'Training Samples {train_samples.shape}')\n",
    "    print(f'Testing Samples {test_samples.shape}')\n",
    "\n",
    "elif project_mode == 'debug':\n",
    "    # Optional, use a small subset of the training and validation data for fast debugging\n",
    "    pass\n",
    "else:\n",
    "    raise ValueError('Unrecognized mode')\n",
    "    \n",
    "print('=> # Train samples = ', len(train_samples))\n",
    "print('=> # Test samples = ', len(test_samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texel</td>\n",
       "      <td>02 01  000006c8 0000066a 0000500002 02  00006b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VB</td>\n",
       "      <td>02 01  000006c8 0000066a 0001a00002 02  00006b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NothingFound</td>\n",
       "      <td>02 01  000006c8 0000066a 0000b00002 02  00006b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Virut</td>\n",
       "      <td>02 01  000006c8 0000066a 0000e00002 02  00006b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Texel</td>\n",
       "      <td>02 01  000006c8 0000066a 0002000002 02  00006b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>NothingFound</td>\n",
       "      <td>02 01  000006c8 0000066a 0001500002 02  00006b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>VB</td>\n",
       "      <td>02 01  000006c8 0000066a 0001400002 02  00006b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>Virut</td>\n",
       "      <td>02 01  000006c8 0000066a 0001700002 02  00006b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>NothingFound</td>\n",
       "      <td>02 01  000006c8 0000066a 0005800002 02  00006b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>Basun</td>\n",
       "      <td>02 01  000006c8 0000066a 0001500002 02  00006b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             label                                              lines\n",
       "0            Texel  02 01  000006c8 0000066a 0000500002 02  00006b...\n",
       "1               VB  02 01  000006c8 0000066a 0001a00002 02  00006b...\n",
       "2     NothingFound  02 01  000006c8 0000066a 0000b00002 02  00006b...\n",
       "3            Virut  02 01  000006c8 0000066a 0000e00002 02  00006b...\n",
       "4            Texel  02 01  000006c8 0000066a 0002000002 02  00006b...\n",
       "...            ...                                                ...\n",
       "3995  NothingFound  02 01  000006c8 0000066a 0001500002 02  00006b...\n",
       "3996            VB  02 01  000006c8 0000066a 0001400002 02  00006b...\n",
       "3997         Virut  02 01  000006c8 0000066a 0001700002 02  00006b...\n",
       "3998  NothingFound  02 01  000006c8 0000066a 0005800002 02  00006b...\n",
       "3999         Basun  02 01  000006c8 0000066a 0001500002 02  00006b...\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GjiNiOVHsMiy"
   },
   "source": [
    "## 1.b. Vectorize: Setup\n",
    "\n",
    "Make one pass over the inputs to identify relevant features/tokens.\n",
    "\n",
    "Suggestion:\n",
    "  - identify tokens (e.g., unigrams, bigrams)\n",
    "  - create a token -> index (int) mapping. Note that you might have a >10K unique tokens. So, you will have to choose a suitable \"vocabulary\" size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DAtmzL6PsMiy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feel free to edit anything in this block\n",
    "\n",
    "# def get_key_idx_map(counter, vocab_size, ukn_token='_ukn_'):\n",
    "#     # counter is a mapping: token -> count\n",
    "#     # build vectorizer using vocab_size most common elements\n",
    "#     key_to_idx, idx_to_key = dict(), dict()\n",
    "#     return key_to_idx, idx_to_key\n",
    "\n",
    "# def helper1():\n",
    "#     pass\n",
    "\n",
    "# def helper2():\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LSMEAcgvsMiy",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feel free to edit anything in this block\n",
    "\n",
    "# MAX_VOCAB_SIZE = 20000\n",
    "\n",
    "# # token_to_idx, idx_to_token = get_key_idx_map(token_counter, MAX_VOCAB_SIZE)\n",
    "\n",
    "# # Save vocab to file\n",
    "# out_path = 'application_vocab_{}.pkl'.format(MAX_VOCAB_SIZE)\n",
    "# with open(out_path, 'wb') as wf:\n",
    "#     dct = vectorize(MAX_VOCAB_SIZE)\n",
    "#     print(len(dct))\n",
    "#     pickle.dump(dct, wf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUefzVjFsMiy"
   },
   "source": [
    "## 1.c. Vectorize Data\n",
    "\n",
    "Use the (token $\\rightarrow$ index) mapping you created before to vectorize your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to edit anything in this block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Tokenize text samples into word uni+bigrams,\n",
    "- Vectorize using tf-idf encoding,\n",
    "- Select only the top 20,000 features from the vector of tokens by discarding tokens that appear fewer than 2 times and using f_classif to calculate feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CD5IqJmXsMiz",
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "\n",
    "# Vectorization parameters\n",
    "# Range (inclusive) of n-gram sizes for tokenizing text.\n",
    "NGRAM_RANGE = (1, 2)\n",
    "\n",
    "# Limit on the number of features. We use the top 20K features.\n",
    "TOP_K = 20000\n",
    "\n",
    "# Whether text should be split into word or character n-grams.\n",
    "# One of 'word', 'char'.\n",
    "TOKEN_MODE = 'word'\n",
    "\n",
    "# Minimum document/corpus frequency below which a token will be discarded.\n",
    "MIN_DOCUMENT_FREQUENCY = 2\n",
    "\n",
    "def vectorize_raw_samples(train_texts, train_labels):\n",
    "    \"\"\"Vectorizes texts as n-gram vectors.\n",
    "\n",
    "    1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams.\n",
    "\n",
    "    # Arguments\n",
    "        train_texts: list, training text strings.\n",
    "        train_labels: np.ndarray, training labels.\n",
    "\n",
    "    # Returns\n",
    "        x_train: vectorized training text \n",
    "    \"\"\"\n",
    "    # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n",
    "    kwargs = {\n",
    "            'ngram_range': NGRAM_RANGE,  # Use 1-grams + 2-grams.\n",
    "            # 'dtype': 'np.float64',\n",
    "            'strip_accents': 'unicode',\n",
    "            'decode_error': 'replace',\n",
    "            'analyzer': TOKEN_MODE,  # Split text into word tokens.\n",
    "            'min_df': MIN_DOCUMENT_FREQUENCY,\n",
    "    }\n",
    "    vectorizer = TfidfVectorizer(**kwargs)\n",
    "\n",
    "    # Learn vocabulary from training texts and vectorize training texts.\n",
    "    x_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "    # Vectorize validation texts.\n",
    "    # x_val = vectorizer.transform(val_texts)\n",
    "\n",
    "    # Select top 'k' of the vectorized features.\n",
    "    selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n",
    "    selector.fit(x_train, train_labels)\n",
    "    x_train = selector.transform(x_train)\n",
    "    # x_val = selector.transform(x_val).astype('float32')\n",
    "    return x_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_samples['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "BtS10ASbsMi0",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Processing: Train\n",
      "=> Processing: Test\n",
      "  (0, 10514)\t0.0009346184028134771\n",
      "  (0, 238)\t0.0009346184028134771\n",
      "  (0, 13748)\t0.0013552086583889062\n",
      "  (0, 10334)\t0.00099042473959292\n",
      "  (0, 8349)\t0.00099042473959292\n",
      "  (0, 10332)\t0.00099042473959292\n",
      "  (0, 8348)\t0.00099042473959292\n",
      "  (0, 16547)\t0.00099042473959292\n",
      "  (0, 8790)\t0.00099042473959292\n",
      "  (0, 17789)\t0.001074775343492852\n",
      "  (0, 8882)\t0.001074775343492852\n",
      "  (0, 17787)\t0.001074775343492852\n",
      "  (0, 11611)\t0.001074775343492852\n",
      "  (0, 15693)\t0.001074775343492852\n",
      "  (0, 15695)\t0.001074775343492852\n",
      "  (0, 13592)\t0.001074775343492852\n",
      "  (0, 15192)\t0.001074775343492852\n",
      "  (0, 8683)\t0.001074775343492852\n",
      "  (0, 15190)\t0.001074775343492852\n",
      "  (0, 8682)\t0.001074775343492852\n",
      "  (0, 9310)\t0.001074775343492852\n",
      "  (0, 8271)\t0.001074775343492852\n",
      "  (0, 13447)\t0.001074775343492852\n",
      "  (0, 8556)\t0.001074775343492852\n",
      "  (0, 13445)\t0.001074775343492852\n",
      "  :\t:\n",
      "  (4999, 13672)\t0.002813556023897211\n",
      "  (4999, 5379)\t0.0006953240225013162\n",
      "  (4999, 6034)\t0.001371592094766557\n",
      "  (4999, 5461)\t0.0006857960473832785\n",
      "  (4999, 5361)\t0.00046762912919626627\n",
      "  (4999, 6200)\t0.0020573881421498356\n",
      "  (4999, 6151)\t0.0014171915912448432\n",
      "  (4999, 6577)\t0.001412401389010121\n",
      "  (4999, 5684)\t0.0014132978544882716\n",
      "  (4999, 5910)\t0.0023445697409853823\n",
      "  (4999, 5733)\t0.0006857960473832785\n",
      "  (4999, 5397)\t0.0010286940710749178\n",
      "  (4999, 6050)\t0.001371592094766557\n",
      "  (4999, 6068)\t0.001371592094766557\n",
      "  (4999, 6694)\t0.002281386935014184\n",
      "  (4999, 5706)\t0.001371592094766557\n",
      "  (4999, 6042)\t0.0017144901184581963\n",
      "  (4999, 6157)\t0.0020573881421498356\n",
      "  (4999, 6100)\t0.001372415132351869\n",
      "  (4999, 11260)\t0.03326110829808901\n",
      "  (4999, 3492)\t0.03223241422701409\n",
      "  (4999, 2929)\t0.00034289802369163926\n",
      "  (4999, 15)\t0.027453273757133256\n",
      "  (4999, 7093)\t0.056235275885428836\n",
      "  (4999, 8162)\t0.24071441263153076\n"
     ]
    }
   ],
   "source": [
    "print('=> Processing: Train')\n",
    "train_data = vectorize_raw_samples(train_samples['lines'], train_samples['label'])\n",
    "\n",
    "print('=> Processing: Test')\n",
    "test_data = vectorize_raw_samples(test_samples['lines'], test_samples['label'])\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0XOHr24usMi0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training_score: 0.83125\n",
      "testing_score: 0.248\n"
     ]
    }
   ],
   "source": [
    "train_x = train_data\n",
    "train_y = train_samples['label']\n",
    "X_test = test_data\n",
    "test_y = test_samples['label']\n",
    "\n",
    "model = KNeighborsClassifier(n_neighbors = 5)\n",
    "model.fit(train_x,train_y)\n",
    "training_score = model.score(train_x,train_y)\n",
    "print(f\"training_score: {training_score}\")\n",
    "\n",
    "# y_pred = model.predict(X_test)\n",
    "testing_score = model.score(X_test,test_y)\n",
    "print(f\"testing_score: {testing_score}\")\n",
    "\n",
    "# print(\"Test Accuracy:\",metrics.accuracy_score(test_y, y_pred))\n",
    "# Suggestions: \n",
    "#\n",
    "# (a) You can use torch.utils.data.TensorDataset to represent the tensors you created previously\n",
    "# trainset = TensorDataset(train_x, train_y)\n",
    "# testset = TensorDataset(test_x, test_y)\n",
    "#\n",
    "# (b) Store your datasets to disk so that you do not need to precompute it every time\n",
    "# torch.save(trainset, 'trainset.pt')\n",
    "# torch.save(testset, 'testset.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_l0tLsEVsMi0"
   },
   "source": [
    "# 2. Train Model\n",
    "\n",
    "You will now train an ML model on the vectorized datasets you created previously.\n",
    "\n",
    "_Note_: Although we often refer to each input as a 'vector' for simplicity, each of your inputs can also be higher dimensional tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UInY1YzksMi0"
   },
   "source": [
    "## 2.a. Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "VnSv0J75sMi0"
   },
   "outputs": [],
   "source": [
    "# Feel free to edit anything in this block\n",
    "\n",
    "def evaluate_preds(y_gt, y_pred):\n",
    "    pass\n",
    "\n",
    "\n",
    "def another_helper(question):\n",
    "    return 42\n",
    "\n",
    "\n",
    "def save_model(model, out_path):\n",
    "    pass\n",
    "\n",
    "\n",
    "def save_data(eval_data, out_path):\n",
    "    with open(out_path, 'wb') as wf:\n",
    "        pickle.dump(eval_data, out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PhbVzVLDsMi1"
   },
   "source": [
    "## 2.b. Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jrUKCNRgsMi1"
   },
   "source": [
    "Describe your model here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "ILB2fBRWsMi1"
   },
   "outputs": [],
   "source": [
    "# Feel free to edit anything in this block\n",
    "\n",
    "class ANN_Network(nn.Module):\n",
    "    def __init__(self, model_parameters):\n",
    "        try:\n",
    "            super(ANN_Network, self).__init__()\n",
    "            layers = []\n",
    "            for in_channel, out_channel in zip([model_parameters['input_size']] + model_parameters['hidden_size'][:-1],\n",
    "                                               model_parameters['hidden_size'][:len(model_parameters['hidden_size'])]):\n",
    "                layers.append(nn.Linear(in_channel, out_channel, bias=True))\n",
    "                layers.append(nn.ReLU())\n",
    "            layers.append(nn.Linear( model_parameters['hidden_size'][-1], model_parameters['out_size'], bias=True))\n",
    "            self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('initializing failed due to ', e)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        try:\n",
    "            return self.layers(x)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print('forward pass failed due to ', e)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 20000)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QO1yPx7YsMi1"
   },
   "source": [
    "## 2.c. Set Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "0k0jLX5ksMi1"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KNeighborsClassifier' object has no attribute 'parameters'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4452/564041919.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'device'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_params\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'learning_rate'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'KNeighborsClassifier' object has no attribute 'parameters'"
     ]
    }
   ],
   "source": [
    "# # Define your hyperparameters here\n",
    "\n",
    "# in_dims = trainset[0][0].shape[0]\n",
    "# out_dims = len(class_to_idx)\n",
    "# ...\n",
    "\n",
    "# # Optimization\n",
    "# n_epochs = ...\n",
    "# batch_size = ...\n",
    "# lr = ...\n",
    "# ...\n",
    "\n",
    "model_params = {\n",
    "    'input_size': train_x[0][0].shape,\n",
    "    'hidden_size' : [2400, 1000, 500, 150],\n",
    "    'out_size' : 10\n",
    "}\n",
    "\n",
    "training_params = {\n",
    "    'device' : torch.device(\"cuda\" if torch.cuda.is_available else 'cpu'),\n",
    "    'batch_size' : 64,\n",
    "    'num_epochs' : 5,\n",
    "    'learning_rate' : 0.001\n",
    "}\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(training_params['device'])\n",
    "optimizer = optim.Adam(model.parameters(), lr=training_params['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ANN_Network(model_params).to(training_params['device'])\n",
    "print(model.parameters)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(total_params) ##### 216590"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NtpgVAO1sMi2"
   },
   "source": [
    "## 2.d. Train your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Co0W2ifGsMi2"
   },
   "outputs": [],
   "source": [
    "best_accuracy = -1\n",
    "train_acc_history = []\n",
    "validation_acc_history = []\n",
    "    \n",
    "for epoch in range(training_params['num_epochs']):\n",
    "    \n",
    "    model.train()\n",
    "    correct_predictions = 0\n",
    "    loss_values = []\n",
    "    train_acc_scores = []\n",
    "\n",
    "    for batch_idx, (images, targets) in enumerate(train_loader):\n",
    "        images = images.view(images.shape[0], -1).to(training_params['device'])\n",
    "        targets = targets.to(training_params['device'])\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss_values.append(loss.item())\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_predictions=(preds==targets).sum().item()\n",
    "        train_acc_scores.append(correct_predictions/targets.shape[0])\n",
    "                      \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch_idx+1) % 100 == 0:\n",
    "            print (f'Epoch {epoch+1} | Step [{batch_idx+1}/{len(train_loader)}] | Loss: {loss.item()} ')\n",
    "\n",
    "    train_acc_history.append((sum(train_acc_scores)/len(train_acc_scores))*100)\n",
    "    print(f'Epoch {epoch+1} | Loss: {(sum(loss_values)/len(loss_values))} | Training Accuracy {train_acc_history[-1]}%')\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct_predictions = 0\n",
    "        validation_acc_scores = []\n",
    "        \n",
    "        for images, targets in iter(validation_loader):\n",
    "            images = images.view(images.shape[0], -1).to(training_params['device'])\n",
    "            targets = targets.to(training_params['device'])\n",
    "            \n",
    "            outputs = model(images)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_predictions = (preds == targets).sum().item()\n",
    "            validation_acc_scores.append(correct_predictions/targets.shape[0])\n",
    "            \n",
    "        validation_acc_history.append((sum(validation_acc_scores)/len(validation_acc_scores))*100)\n",
    "        print(f'Epoch {epoch+1} | Validation Accuracy {validation_acc_history[-1]}%')\n",
    "        \n",
    "        if validation_acc_history[-1]>best_accuracy:\n",
    "            best_accuracy = validation_acc_history[-1]\n",
    "            print('Saving the model...')\n",
    "            torch.save(model.state_dict(), f\"Accuracy_{best_accuracy}_batchsize_{training_params['batch_size']}_lr_{training_params['learning_rate']}.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3afVBWVKsMi2"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "# Example:\n",
    "# for epoch in range(n_epochs):\n",
    "#     ... train ...\n",
    "#     ... validate ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z5w-7O5jsMi2"
   },
   "source": [
    "## 2.e. Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CMbzX1h4sMi2"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_GE1BQjsMi3"
   },
   "source": [
    "## 2.f. Save Model + Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Xvo--GIsMi3"
   },
   "outputs": [],
   "source": [
    "#\n",
    "#\n",
    "# ------- Your Code -------\n",
    "#\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W-UQbfCrsMi3"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uLD6dur1sMi3"
   },
   "source": [
    "# 3. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1QRKxLsPsMi3"
   },
   "source": [
    "## 3.a. Summary: Main Results\n",
    "\n",
    "Summarize your approach and results here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNKqJAoasMi4"
   },
   "source": [
    "## 3.b. Discussion\n",
    "\n",
    "Enter your final summary here.\n",
    "\n",
    "For instance, you can address:\n",
    "- What was the performance you obtained with the simplest approach?\n",
    "- Which vectorized input representations helped more than the others?\n",
    "- Which malwares are difficult to detect and why?\n",
    "- Which approach do you recommend to perform malware classification?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Task_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
